Gesture Recognition Research Papers - Academia.edu
      Skip to main content
    
Academia.edu no longer supports Internet Explorer.To browse Academia.edu and the wider internet faster and more securely, please take a few seconds to upgrade your browser.
Log InSign UpLog InSign Upmore Job BoardAboutPressBlogPeoplePapersTermsPrivacyCopyright We're Hiring! Help Centerless 
Gesture Recognition9,305 FollowersRecent papers in Gesture RecognitionTop PapersMost Cited PapersMost Downloaded PapersNewest PapersPeopleMulti-spectral and multi-perspective video arrays for driver body tracking and activity analysisSave to LibraryDownloadby Mohan Trivedi•  20  Cognitive Science, Human Computer Interaction, Computer Vision, Modal AnalysisHuman Action Recognition Using Multi-View Image Sequences FeaturesSave to LibraryDownloadby Dr. Mohiuddin Ahmad•  16  Computer Vision, Principal Component Analysis, Gesture Recognition, ProceedingsHand gesture interaction using color-based method for tabletop interfacesSave to LibraryDownloadby Abdelkader Bellarbi•  7  Computer Science, Computer Vision, Augmented Reality, Gesture RecognitionSMART VIDEO-BASED SIGN LANGUAGE APP: IMPACTS ON COMMUNICATION FOR DEAF AND DUMB INDIVIDUALSLife is a blessing from the graces of God that he granted to all His creatures. God has excelled in creating this life in its most beautiful form, making the difference of people and the difference of graces among them a cornerstone for... moreLife is a blessing from the graces of God that he granted to all His creatures. God has excelled in creating this life in its most beautiful form, making the difference of people and the difference of graces among them a cornerstone for enjoying life. Created nature around him, which fascinates hearts, and some enjoy hearing the melody of nature and the chirping of birds and the chants of the seas. The situation regarding the deaf and dumb category is different, because life on a daily basis faces the deaf and dumb category with various difficulties, some of which are similar to what other natural individuals face, Some of the others are his own, that is, they are caused by the problems he suffers because of his disability, and the deaf-dumb tries to continue living relying on his attempt to be able to adapt to the conditions of his life, so they succeed and fail at times. The greater challenge for the deafdumb is to strive all possible ways to communicate with the society easily and confidently. They face many problems because most of the individuals they interact may lack knowledge of communicating using sign language. This research aims to reach solutions to overcome this problem by proposing an application to communicate for the Deaf and dumb. This application will help the public to understand the sign language used by deaf and dumb individuals. Therefore, the deaf and dumb group can communicate with people who do not know sign language without feeling embarrassed.Save to LibraryDownloadby IJIRAE - International Journal of Innovative Research in Advanced Engineering and +1Rayan Nasser•  6  Natural Language Processing, Sign Languages, Assistive Technology, Speech RecognitionReal-time American sign language recognition using desk and wearable computer based videoSave to LibraryDownloadby Shadman Shahriar•  18  Information Systems, Computer Vision, Sign Language, Pattern RecognitionCapturing the Human Action Semantics using a Query-By-ExampleSave to LibraryDownloadby Paolo Puliti•  2  Gesture Recognition, Query by ExampleReconocimiento de Posturas en secuencias de video usando firma Punto-ContornoA research area in Computer Vision focuses on the identification of articulated objects, such as human actions and movements of the hand, which can be used in human-computer interaction, surveillance, and other tracking systems. Two... moreA research area in Computer Vision focuses on the identification of articulated objects, such as human actions and movements of the hand, which can be used in human-computer interaction, surveillance, and other tracking systems. Two problems arise: identify when two articulated objects in different stances are in the same class of objects, and differentiate the distinct positions of the same object. In both cases, it is necessary to know how correspond the different points or regions of such objects standing in different attitudes. This article presents the Contour-Point Signature; a point descriptor that allows to establish a method to achieve the better matching of points between two figures, and to thus obtain a transformation which relates them. With this descriptor, we can achieve more accurate shape features and implement more efficient retrieval under multi-resolution. In addition, CPS is robust to rigid translation, scaling, rotation and independent of the origin point. A measure of dissimilarity between two figures for classifying various human postures in a video sequence is also presented.Save to LibraryDownloadby Waldemar Villamayor-Venialbo•  39  Computer Vision, Robot Vision, Object Recognition (Computer Vision), Image Recognition (Computer Vision)Tabletop Collaboration Through Tangible InteractionsSave to LibraryDownloadby Sriram Subramanian•  8  Computer Science, Human Computer Interaction, Gesture Recognition, Digital ControlOn the usability of gesture interfaces in virtual reality environmentsSave to LibraryDownloadby Márcio Cabral•  3  Computer Vision, Gesture Recognition, Virtual RealityQuickSet: Multimodal interaction for distributed applicationsSave to LibraryDownloadby Liang Chen•  7  Natural Language Processing, Multimodal Interaction, Speech Recognition, Gesture RecognitionTURKISH SIGN LANGUAGE RECOGNITION USING HIDDEN MARKOV MODELIn past years, there were a lot of researches made in order to provide more accurate and comfortable interaction between human and machine. Developing a system which recognizes human gestures, is an important study to improve interaction... moreIn past years, there were a lot of researches made in order to provide more accurate and comfortable interaction between human and machine. Developing a system which recognizes human gestures, is an important study to improve interaction between human and machine. Sign language is a way of communication for hearing-impaired people which enables them to communicate among themselves and with other people around them. Sign language consists of hand gestures and facial expressions. During the past 20 years, researches were made to facilitate communication of hearing-impaired people with others. Sign language recognition systems are designed in various countries. This paper presents a sign language recognition system, which uses Kinect camera to obtain skeletal model. Our aim was to recognize expressions, which are used widely in Turkish Sign Language (TSL). For that purpose we have selected 15 words/expressions randomly (repeated 4 times each by 3 different signers) which belong to Turkish Sign Language. We have used 180 records in total. Videos are recorded using Microsoft Kinect Camera and Nui Capture. Joint angles and joint positions have been used as features of gesture and achieved close to 100% recognition rates.Save to LibraryDownloadby Computer Science & Information Technology (CS & IT) Computer Science Conference Proceedings (CSCP)•  5  Gesture Recognition, hidden Markov model, Microsoft Kinect, Turkish Sign Language RecognitionMaths mission: a case study of gesture-based technology in the mathematics classroomSave to LibraryDownloadby Prof. Dr. Alison McNamara•  6  Information Technology, Serious Games, Mathematics Education, Game Based LearningReal-time hand gesture telerobotic system using fuzzy c-means clusteringSave to LibraryDownloadby Juan Wachs•  13  Fuzzy set theory, Fuzzy Systems, Gesture Recognition, Control SystemsPremotor cortex and the recognition of motor actionsSave to LibraryDownloadby Semra Özdemir•  5  Gesture Recognition, Communication System, Mirror Neuron, Premotor cortexEmotionally aware automated portrait paintingSave to LibraryDownloadby Simon Colton•  12  Computer Vision, Art, Affective Computing, Machine VisionIntention prediction approach to interact naturally with the microworldSave to LibraryDownloadby Sinan D Haliyo and +1Laura Cohen•  7  Computational Modeling, Gesture Recognition, Virtual Reality, Predictive modelsA Hand Gesture Recognition Framework and Wearable Gesture-Based Interaction Prototype for Mobile DevicesSave to LibraryDownloadby Mumtaz Alam•  5  Human Computer Interaction, Machine Learning, Wireless Communications, Gesture RecognitionThe cognitive cerebellum: A big role in psychology for the 'little brain'?Save to LibraryDownloadby Eric Parkins•  257  Evolutionary Biology, Neuroscience, Psychology, Behavioural ScienceIntelligent Interaction for Human-Friendly Service Robot in Smart House EnvironmentSave to LibraryDownloadby Smart House•  14  Computational Intelligence, Gesture Recognition, Complex System, People with DisabilitiesHand gesture recognition and virtual game control based on 3D accelerometer and EMG sensorsSave to LibraryDownloadby Vuokko  Lantz•  7  Human Computer Interaction, Gesture Recognition, hidden Markov model, Intelligent User InterfacesAcume: A new visualization tool for understanding facial expression and gesture dataSave to LibraryDownloadby Daniel McDuff•  14  Open Source Software, Face Recognition, Gesture Recognition, Facial expressionHand gesture recognition algorithm based on grayscale histogram of the imageThis paper is about one more method for the hand gesture recognition algorithms. Described system in this paper doesn't require wearing any device or gloves for the subject's hand. For detecting hand motion, simple stereo camera is... moreThis paper is about one more method for the hand gesture recognition algorithms. Described system in this paper doesn't require wearing any device or gloves for the subject's hand. For detecting hand motion, simple stereo camera is needed. The actual difference of suggested method in this paper with previous works is we are using grayscale histogram to define depth threshold of calculated disparity map.Save to LibraryDownloadby Rustam Rakhimov•  3  Gesture Recognition, Information, Hand Gesture RecognitionAn update on the Conceptual–Production Systems model of apraxia: Evidence from strokeSave to LibraryDownloadby vessela stamenova•  20  Psychology, Cognitive Science, Performance, Nonverbal CommunicationVisual interpretation of hand gestures for human-computer interaction: a reviewSave to LibraryDownloadby Thomas Huang•  14  Information Systems, Human Computer Interaction, Computer Vision, Computational ModelingEvaluation of Gender Classification Methods with Automatically Detected and Aligned FacesWe present a systematic study on gender classification with automatically detected and aligned faces. We experimented with 120 combinations of automatic face detection, face alignment and gender classification. One of the findings was... moreWe present a systematic study on gender classification with automatically detected and aligned faces. We experimented with 120 combinations of automatic face detection, face alignment and gender classification. One of the findings was that the automatic face alignment methods did not increase the gender classification rates. However, manual alignment increased classification rates a little, which suggests that automatic alignment would be useful when the alignment methods are further improved. We also found that the gender classification methods performed almost equally well with different input image sizes. In any case, the best classification rate was achieved with a support vector machine. A neural network and Adaboost achieved almost as good classification rates as the support vector machine and could be used in applications where classification speed is considered more important than the best possible classification accuracy.Save to LibraryDownloadby Roope Raisamo•  21  Information Systems, Algorithms, Artificial Intelligence, Computer VisionInfotainment devices control by eye gaze and gesture recognition fusionSave to LibraryDownloadby Hafiz Habib•  8  Video Processing, Gesture Recognition, Gaze Direction, Intensive Care UnitA SIGNATURE BASED DRAVIDIAN SIGN LANGUAGE RECOGNITION BY SPARSE REPRESENTATIONSign language is a visual-gestural language used by deaf-dumb people for communication. As normal people are unfamiliar of sign language, the hearing-impaired people find it difficult to communicate with them. The communication gap... moreSign language is a visual-gestural language used by deaf-dumb people for communication. As normal people are unfamiliar of sign language, the hearing-impaired people find it difficult to communicate with them. The communication gap between the normal and the deaf-dumb people can be bridged by means of Human–Computer Interaction. The objective of this paper is to convert the Dravidian (Tamil) sign language into text. The proposed method recognizes 12 vowels, 18 consonants and a special character " Aytham " of Tamil language by a vision based approach. In this work, the static images of the hand signs are obtained a web/digital camera. The hand region is segmented by a threshold applied to the hue channel of the input image. Then the region of interest (i.e. from wrist to fingers) is segmented using the reversed horizontal projection profile and the Discrete Cosine transformed signature is extracted from the boundary of hand sign. These features are invariant to translation, scale and rotation. Sparse representation classifier is incorporated to recognize 31 hand signs. The proposed method has attained a maximum recognition accuracy of 71% in a uniform background.Save to LibraryDownloadby International Journal on Natural Language Computing (IJNLC)•  3  Computer Science, Image Processing, Gesture RecognitionSixth sense technology... 2. Components Used Poongodi, Int. J. EnCoTe, 2012, v0102, 09 - 20 ISSN ; 2277 - 9377 IJECST | March - April 2012 Available online@www.ijecst.com 9 Page 2. ... F) FunctioningPoongodi, Int. J. EnCoTe, 2012, v0102, 09 - 20 ISSN ; 2277 -... more... 2. Components Used Poongodi, Int. J. EnCoTe, 2012, v0102, 09 - 20 ISSN ; 2277 - 9377 IJECST | March - April 2012 Available online@www.ijecst.com 9 Page 2. ... F) FunctioningPoongodi, Int. J. EnCoTe, 2012, v0102, 09 - 20 ISSN ; 2277 - 9377 ...Save to Libraryby Muthu Kumar•  7  Human Computer Interaction, Augmented Reality, Gesture Recognition, Mobile DeviceDesign and Development of a Virtual Dolphinarium for Children With AutismSave to LibraryDownloadby alfred chia•  20  Computer Graphics, Human Computer Interaction, Pediatrics, Biomedical EngineeringInterface design for serious game visual strategies - The case study of Imago BononiaeUnder the V-Must project, “Imago Bononiae” (2013) stands as a real example of how to build-up a reliable and efficient experimentation caring about the quality and effectiveness of a gesture-based Virtual Museum application in relation... moreUnder the V-Must project, “Imago Bononiae”(2013) stands as a real example of how to build-up a reliable andefficient experimentation caring about the quality andeffectiveness of a gesture-based Virtual Museum application inrelation with game design patterns. This paper focuses indeed onthe user-centric gesture design and progressive gestural skills(rewards) that user can acquire in order to gain an engagingexperience and a massive comprehension of large urban contextsmediated by visual strategies, while enabling spatial andvolumetric comparisons. Structured as a serious game, theproject foresaw a user experience evaluation carried out inoccasion of Digital Heritage Expo, held in Marseille in november2013. During the event, “Imago Bononiae” was studied tounderstand more on the interaction’s aspects that take placebetween system and user. The visual design features that mostlyconnote the main interface and that, consequently, influence thebehavior of users have been studied, like visibility, reliability andmemorability. The affordance of the whole system has been thenobserved. Results presented show that “Imago Bononiae” hasproved to be suitable for the large audience given its facilitatedusability and the well-structured game strategySave to LibraryDownloadby Bruno Fanini and +1Alfonsina  Pagano•  8  Serious Games, Natural User Interfaces, Gesture Recognition, 3D Modelling (Architecture)A Na¨ive Bayes Classifier with Distance Weighting for Hand-Gesture RecognitionWe present an effective and fast method for static hand gesture recognition. This method is based on classifying the different gestures according to geometric-based invariants which are obtained from image data after segmentation; thus,... moreWe present an effective and fast method for static hand gesture recognition. This method is based on classifying the different gestures according to geometric-based invariants which are obtained from image data after segmentation; thus, unlike many other recognition methods, this method is not dependent on skin color. Gestures are extracted from each frame of the video, with a static background. The segmentation is done by dynamic extraction of background pixels according to the histogram of each image. Gestures are classified using a weighted K-Nearest Neighbors Algorithm which is combined with a naive Bayes approach to estimate the probability of each gesture type.Save to LibraryDownloadby Dr. Pujan Ziaie•  7  Computer Science, Image Processing, Gesture Recognition, Human Robot InteractionData-Driven Scenario Specification for AV–VRU Interactions at Urban RoundaboutsDetailed specifications of urban traffic from different perspectives and scales are crucial for understanding and predicting traffic situations from the view of an autonomous vehicle (AV). We suggest a data-driven specification scheme for... moreDetailed specifications of urban traffic from different perspectives and scales are crucial for understanding and predicting traffic situations from the view of an autonomous vehicle (AV). We suggest a data-driven specification scheme for maneuvers at different design elements of the built infrastructure and focus on urban roundabouts in Germany. Based on real observations, we define classes of maneuvers, interactions and driving strategies for cyclists, pedestrians and motorized vehicles and define a matrix for merging different maneuvers, resulting in more complex interactions. The sequences of these interactions, which partially consist of explicit communications, are extracted from real observations and adapted into microscopic traffic flow simulations. The simulated maneuver sequences are then visualized in 3D environments and experienced by bicycle simulator test subjects. Using trajectory segments (in fictional space) from two conducted simulator studies, we relate the record...Save to LibraryDownloadby Fritz Busch•  20  Transportation Engineering, Communication, Virtual Reality (Computer Graphics), Transportation StudiesDutch Named Entity Recognition and De-Identification Methods for the Human Resource DomainThe human resource (HR) domain contains various types of privacy-sensitive textual data, such as e-mail correspondence and performance appraisal. Doing research on these documents brings several challenges, one of them anonymisation. In... moreThe human resource (HR) domain contains various types of privacy-sensitive textual data, such as e-mail correspondence and performance appraisal. Doing research on these documents brings several challenges, one of them anonymisation. In this paper, we evaluate the current Dutch text de-identification methods for the HR domain in four steps. First, by updating one of these methods with the latest named entity recognition (NER) models. The result is that the NER model based on the CoNLL 2002 corpus in combination with the BERTje transformer give the best combination for suppressing persons (recall 0.94) and locations (recall 0.82). For suppressing gender, DEDUCE is performing best (recall 0.53). Second NER evaluation is based on both strict de-identification of entities (a person must be suppressed as a person) and third evaluation on a loose sense of de-identification (no matter what how a person is suppressed, as long it is suppressed). In the fourth and last step a new kind of NER dataset is tested forrecognising job titles in tezts.Save to LibraryDownloadby International Journal on Natural Language Computing (IJNLC)•  17  Human Resource Development, Facial Recognition, Pattern Recognition, Object Recognition (Pattern Recognition)Sign language recognition by combining statistical DTW and independent classificationSave to LibraryDownloadby Emile Hendriks•  25  Information Systems, Algorithms, Artificial Intelligence, Sign LanguageHANDTALK Interpreter for the Differently Abled: A Review—Many people can't talk due to speech problem like a dumb one or they have never heard the pronunciations of the word/symbol like a deaf one and that's why those people can't communicate with others who don't know the sign language. We... more—Many people can't talk due to speech problem like a dumb one or they have never heard the pronunciations of the word/symbol like a deaf one and that's why those people can't communicate with others who don't know the sign language. We have come up with a novel idea of a system that will convert the hand movements (Gestures) into the voice and display the message and allow the deaf and dumb to express them better. A sensor equipped glove needs to be worn on the hand and depending on the various gestures made by individual, the gesture will be interpreted to the corresponding voice and display message by the device. Further, that particular message can be transmitted as a voice or text to the doctor's phone as well as to the concerned person. For this we are using flex sensors, MEMS (Micro-Electro Mechanical System) accelerometer, microcontroller, speech IC, speakers, LCD display and GSM Module.Save to LibraryDownloadby Sachin  Verma and +1Gunjeet Saini•  4  Automatic Control, Home automation, Gesture Recognition, Embedded SystemA Quality Framework For User Interaction In Virtual Environments Using Wearable Devices— Gesture recognition has been considered as one of the most effective input methods to interact with virtual environments (VEs). The skeleton tracking techniques which have been widely used for gesture recognition purposes showed common... more— Gesture recognition has been considered as one of the most effective input methods to interact with virtual environments (VEs). The skeleton tracking techniques which have been widely used for gesture recognition purposes showed common accuracy issues with Micro-gestures that can affect user's enjoyment. In this paper, we propose a multimodal interaction technique and test it using a designed wearable head-mounted tracker as a measurement instrument. We also designed a theoretical framework to resolve the weaknesses of Micro-Gestures recognition in CAVE (Cave Automatic Virtual Environment). The effectiveness of proposed method and its impact of user's joyfulness has been tested by a 3D gesture-based interface. The results showed improvement in user's enjoyment using the designed measuring and input method for navigation within a 3D CAVE by improving system's accuracy.Save to LibraryDownloadby Mahdi Babaei•  8  Virtual Environments, User Experience (UX), Wearable Computing, User Centred DesignHCI based Application for Playing Computer GamesThis paper describes a command interface for games based on hand gestures and voice command defined by postures, movement and location. The system uses computer vision requiring no sensors or markers by the user. In voice command the... moreThis paper describes a command interface for games based on hand gestures and voice command defined by postures, movement and location. The system uses computer vision requiring no sensors or markers by the user. In voice command the speech recognizer, recognize the input from the user. It stores and passes command to the game, action takes place. We propose a simple architecture for performing real time colour detection and motion tracking using a webcam. The next step is to track the motion of the specified colours and the resulting actions are given as input commands to the system. We specify blue colour for motion tracking and green colour for mouse pointer. The speech recognition is the process of automatically recognizing a certain word spoken by a particular speaker based on individual information included in speech waves. This application will help in reduction in hardware requirement and can be implemented in other electronic devices also.Save to LibraryDownloadby J4R - Journal for Research and +1B. Vengataramanan•  10  Human Computer Interaction, Computer Vision, Gesture Recognition, Engineering and Computer ScienceCriteria, Challenges and Opportunities for Gesture Programming LanguagesAn increasing number of today's consumer devices such as mobile phones or tablet computers are equipped with various sensors. The extraction of useful information such as gestures from sensor-generated data based on mainstream imperative... moreAn increasing number of today's consumer devices such as mobile phones or tablet computers are equipped with various sensors. The extraction of useful information such as gestures from sensor-generated data based on mainstream imperative languages is a notoriously difficult task. Over the last few years, a number of domain-specific programming languages have been proposed to ease the development of gesture detection. Most of these languages have adopted a declarative approach allowing programmers to describe their gestures rather than having to manually maintain a history of event data and intermediate gesture results. While these declarative languages represent a clear advancement in gesture detection, a number of issues are still unresolved. In this paper we present relevant criteria for gesture detection and provide an initial classification of existing solutions based on these criteria in order to foster a discussion and identify opportunities for future gesture programming languages.Save to LibraryDownloadby Beat Signer•  35  Engineering, Computer Science, Software Engineering, Programming LanguagesGestures without libraries, toolkits or training: a $1 recognizer for user interface prototypesSave to LibraryDownloadby Jacob Wobbrock•  10  User Interface, Gesture Recognition, Rapid Prototyping, User interfacesSensor pillow system: Monitoring cardio-respiratory and posture movements during sleepSave to LibraryDownloadby Shongpun Lokavee•  5  Gesture Recognition, Wireless Network, Point of Care, Sensor ArrayUnconscious Mind: a Gestalt sensorimotor information processor, capable of embodied 'emotional' cognition, 'automatic' control of behavior, and dream production.Save to LibraryDownloadby Eric Parkins•  196  Neuroscience, Psychology, Behavioural Science, Clinical PsychologyAsia-Pacific Gesture Recognition & Touchless Sensing Market worth $4.18 Billion By 2018 Save to LibraryDownloadby Market Research•  4  Semiconductors, Biometrics, Asia Pacific Region, Gesture RecognitionSixth Sense TechnologyThis paper deals with the new emerging technology The Sixth Sense. It's a wearable mobile interface that augments the physical world around us with the digitalised machine world. This technology bridges the gap between the digital world... moreThis paper deals with the new emerging technology The Sixth Sense. It's a wearable mobile interface that augments the physical world around us with the digitalised machine world. This technology bridges the gap between the digital world and real world just by allowing the interaction of humans with the machines through simple hand gestures. The category under which this technology falls is the Augmented Reality Technology. This paper eyes on the possible applications and outcomes of such technology and the advantages and drawbacks of the technology after sourcing or implementing it into real world for use. The most important are the technical challenges faced to get succeeded in future and enhancing it more for future and optimal use.Save to LibraryDownloadby JASH MATHEW•  5  Human Computer Interaction, Augmented Reality, Gesture Recognition, SIXTH SENSE TECHNOLOGYWhat do learners make of teachers' gestures in the language classroom?Save to LibraryDownloadby Daniela Sime•  4  Teaching English as a Second Language, Gesture Studies, Gesture, Gesture RecognitionIntuitive Control of 3 Omni-wheel based Mobile Platform using Leap MotionAutonomous and remotely controlled mobile robots are used extensively in industries and are slowly becoming a norm in day-today life. They can be manually controlled using devices such as joysticks or by using mobile phone applications,... moreAutonomous and remotely controlled mobile robots are used extensively in industries and are slowly becoming a norm in day-today life. They can be manually controlled using devices such as joysticks or by using mobile phone applications, through Bluetooth or similar technologies. In this paper, the authors propose usage of Leap Motion device which can track hands of human users. By using the gestures, the human can operate a mobile robot. For the demonstration, the authors propose its usage on a 3 Omni-wheel based mobile platform. First, the mathematical model of the robot was formulated and simulated in V-REP software for various types of motion. Then, a physical prototype was developed, which was integrated with both Bluetooth based mobile phone application and Leap Motion device. Field trials and survey of 30 people was carried out, where both methods were perceived to be of similar ease of use and intuitiveness. However, the authors feel the results of Leap Motion control may improve with subsequent usage by the users.Save to LibraryDownloadby Devasena Pasupuleti and +1Rajeevlochana Chittawadigi•  9  Mechanical Engineering, Robotics, Mobile Robotics, GestureHand Gesture Recognition Implementation using Python, OpenCVThis project and experiment were conducted with the aim of utilizing the human hands as an object to operate computers. It is intended to support and use technologies in the field of contactless shopping/payments. The program is developed... moreThis project and experiment were conducted with the aim of utilizing the human hands as an object to operate computers. It is intended to support and use technologies in the field of contactless shopping/payments.The program is developed by using python programming language with the help of additional libraries such as OpenCV.In order to use this program, the person needs to be in front of a computer webcam. The webcam will be used to recognize the shape and the pattern of the presenters’ hands. The program will display results of recognized hand patterns of gestures on a live video frame stream. The result of this project is a program that can be used for improve the user experience of contactless systems and make safer transactions in a time of global pandemic of 2020, where social distancing is one of the main things to consider.Save to LibraryDownloadby Abbosjon Kudratov•  6  Image Processing, Gesture Recognition, Python, OpenCv or Computer VisionTHETIS: THree Dimensional Tennis Shots - A human action datasetThe detection and classification of human movements, as a joint field of Computer Vision and Pattern Recognition, is used with an increasing rate in applications designed to describe human activity. Such applications require efficient... moreThe detection and classification of human movements, as a joint field of Computer Vision and Pattern Recognition, is used with an increasing rate in applications designed to describe human activity. Such applications require efficient methods and tools for the automatic analysis and classification of motion capture data, which constitute an active field of research. To facilitate the development and the benchmarking of methods for action recognition, several video collections have previously been proposed. In this paper, we present a new video database that can be used for an objective comparison and evaluation of different motion analysis and classification methods. The database contains video clips that capture the 3D motion of individuals. To be more specific, the set consists of 8374 video clips, which contain 12 different types of tennis actions performed by 55 individuals, captured by Kinect. Kinect provides the depth map of motion data and helps to extract the 3D skeletal joint connections. Performing experiments using state of the art algorithms, the database shows to be very challenging. It contains very similar to each other actions, offering the opportunity to algorithms dedicated to gaming and athletics, to be developed and tested. The database is freely available for research purposes.Save to LibraryDownloadby Kostas Karpouzis•  5  Computer Vision, Game studies, Gesture, Gesture RecognitionA model for Real-time Recognition and Textual Representation of Malaysian Sign  Language through Image ProcessingIn this paper we discuss a stand-alone system to allow the deaf or hard-of-hearing people and normal people to communicate with each other easily and fluently. We purpose a model for recognizing Malaysian Sign Language through image... moreIn this paper we discuss a stand-alone system to allow the deaf or hard-of-hearing people and normal people to communicate with each other easily and fluently. We purpose a model for recognizing Malaysian Sign Language through image processing techniques and converting the visual information into textual information at real-time. In order to implement a real time hand gesture recognition system, video footage will be obtained from digital camera or cellphone camera, then hand position and location will be marked and cropping will be done to isolate them. Then the hand gestures will be recognized through image processing and matched to a prebuilt database of gestures which will be used for textual conversion on the screen. In the final step the normal person will type the text and its equivalent animation of hand gestures will be presented. Through this system, real-time recognition of Malaysian Sign Language and textual representation is done, giving more accurate results at least possible time. It will not only benefit the deaf and dumb people of Malaysia but also could be used in various applications in the technology field. This system provides the flexibility to learn Malaysian Sign Language at personal pace, at anytime and anywhere at home or at workplace.Save to LibraryDownloadby Zeeshan Bhatti•  10  Computer Vision, Image Processing, Sign Languages, Object Recognition (Computer Vision)3D Skeleton-based Human Action Classification: a SurveyIn recent years, there has been a proliferation of works on human action classification from depth sequences. These works generally present methods and/or feature representations for the classification of actions from sequences of 3D... moreIn recent years, there has been a proliferation of works on human action classification from depth sequences. These works generally present methods and/or feature representations for the classification of actions from sequences of 3D locations of human body joints and/or other sources of data, such as depth maps and RGB videos.This survey highlights motivations and challenges of this very recent research area by presenting technologies and approaches for 3D skeleton-based action classification. The work focuses on aspects such as data pre-processing, publicly available benchmarks and commonly used accuracy measurements. Furthermore, this survey introduces a categorization of the most recent works in 3D skeleton-based action classification according to the adopted feature representation.This paper aims at being a starting point for practitioners who wish to approach the study of 3D action classification and gather insights on the main challenges to solve in this emerging field.Save to LibraryDownloadby Liliana Lo Presti•  12  Robotics, Computer Science, Artificial Intelligence, Human Computer InteractionGESTURE RECOGNITION SYSTEMCommunication plays a crucial part in human life. It encourages a man to pass on his sentiments, feelings and messages by talking, composing or by utilizing some other medium. Gesture based communication is the main method for... moreCommunication plays a crucial part in human life. It encourages a man to pass on his sentiments, feelings and messages by talking, composing or by utilizing some other medium. Gesture based communication is the main method for Communication for the discourse and hearing weakened individuals. Communication via gestures is a dialect that utilizations outwardly transmitted motions that consolidates hand signs and development of the hands, arms, lip designs, body developments and outward appearances, rather than utilizing discourse or content, to express the individual's musings. Gestures are the expressive and important body developments that speaks to some message or data. Gestures are the requirement for hearing and discourse hindered, they pass on their message to others just with the assistance of motions. Gesture Recognition System is the capacity of the computer interface to catch, track and perceive the motions and deliver the yield in light of the caught signals. It enables the clients to interface with machines (HMI) without the any need of mechanical gadgets. There are two sorts of sign recognition methods: image-based and sensor-based strategies. Image-based approach is utilized as a part of this project that manages communication via gestures motions to distinguish and track the signs and change over them into the relating discourse and content.Save to LibraryDownloadby IJCSMC  Journal and +2Ananya AlvaManjushree A. N.•  5  Computer Science, Information Technology, Computer Engineering, Computer NetworksNextLast »Related TopicsContext-Aware ComputingFollowFollowingGestureFollowFollowingHypermediaFollowFollowingWeb ScienceFollowFollowingHand Gesture Recognition SystemFollowFollowingComputer VisionFollowFollowingLinked DataFollowFollowingGesture StudiesFollowFollowingKinectFollowFollowingHuman Computer InteractionFollowFollowing 71.6 million researchers use this site every month. Ads help cover our server costs.
×CloseLog InLog in with FacebookLog in with GoogleorEmailPasswordRemember me on this computeror reset passwordEnter the email address you signed up with and we'll email you a reset link.
Need an account? Click here to sign up
AboutPressBlogPeoplePapersTopicsAcademia BiologyAcademia EngineeringAcademia MedicineJob Board We're Hiring! Help CenterFind new research papers in:PhysicsChemistryBiologyHealth SciencesEcologyEarth SciencesCognitive ScienceMathematicsComputer ScienceTermsPrivacyCopyrightAcademia ©2023